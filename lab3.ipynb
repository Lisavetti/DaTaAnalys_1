{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYlNQ+RvnHGq+ugMpwgo+L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lisavetti/DaTaAnalys_1/blob/main/lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'fraud_dataset.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Separate features and target variable\n",
        "target = 'fraud_label'  # Update this if the target column name is different\n",
        "X = df.drop(target, axis=1)\n",
        "y = df[target]\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# Create a preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(), categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply the preprocessing pipeline\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)\n"
      ],
      "metadata": {
        "id": "K2LeWKsLyzqh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "print(\"Class weights:\", class_weight_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwqkEFHfzPCV",
        "outputId": "da700c32-36f0-45b3-fb2f-1342d62fa27f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: 0.6415094339622641, 1: 2.2666666666666666}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "s7Wjq589zQ7b"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
        "                    validation_split=0.2, class_weight=class_weight_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNVSKujgzVog",
        "outputId": "5e4262e7-3f8b-40f8-e18b-d23b5acbcb17"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.5946 - accuracy: 0.5556 - val_loss: 0.6792 - val_accuracy: 0.5714\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.6893 - accuracy: 0.5000 - val_loss: 0.6646 - val_accuracy: 0.5714\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.6456 - accuracy: 0.4815 - val_loss: 0.6511 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.6655 - accuracy: 0.5370 - val_loss: 0.6385 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.6251 - accuracy: 0.5926 - val_loss: 0.6271 - val_accuracy: 0.5714\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.6059 - accuracy: 0.6111 - val_loss: 0.6170 - val_accuracy: 0.5714\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.6261 - accuracy: 0.5926 - val_loss: 0.6070 - val_accuracy: 0.6429\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.6031 - accuracy: 0.6296 - val_loss: 0.5976 - val_accuracy: 0.6429\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5785 - accuracy: 0.5185 - val_loss: 0.5881 - val_accuracy: 0.6429\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5752 - accuracy: 0.6667 - val_loss: 0.5785 - val_accuracy: 0.7143\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.5720 - accuracy: 0.6481 - val_loss: 0.5690 - val_accuracy: 0.7143\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5650 - accuracy: 0.7222 - val_loss: 0.5598 - val_accuracy: 0.7143\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5442 - accuracy: 0.7037 - val_loss: 0.5506 - val_accuracy: 0.7143\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.5653 - accuracy: 0.6852 - val_loss: 0.5419 - val_accuracy: 0.7143\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4948 - accuracy: 0.7407 - val_loss: 0.5332 - val_accuracy: 0.7143\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.4903 - accuracy: 0.7037 - val_loss: 0.5238 - val_accuracy: 0.7143\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5811 - accuracy: 0.7037 - val_loss: 0.5146 - val_accuracy: 0.7143\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4976 - accuracy: 0.7222 - val_loss: 0.5058 - val_accuracy: 0.7143\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.5240 - accuracy: 0.6481 - val_loss: 0.4969 - val_accuracy: 0.7143\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.4813 - accuracy: 0.7222 - val_loss: 0.4882 - val_accuracy: 0.7143\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5154 - accuracy: 0.7037 - val_loss: 0.4804 - val_accuracy: 0.7143\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.4389 - accuracy: 0.7593 - val_loss: 0.4720 - val_accuracy: 0.7143\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.4206 - accuracy: 0.8148 - val_loss: 0.4640 - val_accuracy: 0.7857\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5497 - accuracy: 0.7593 - val_loss: 0.4565 - val_accuracy: 0.7857\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4074 - accuracy: 0.7778 - val_loss: 0.4495 - val_accuracy: 0.7857\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.4739 - accuracy: 0.7778 - val_loss: 0.4423 - val_accuracy: 0.7857\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.3989 - accuracy: 0.8889 - val_loss: 0.4352 - val_accuracy: 0.7857\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4388 - accuracy: 0.8333 - val_loss: 0.4285 - val_accuracy: 0.7857\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3990 - accuracy: 0.8333 - val_loss: 0.4216 - val_accuracy: 0.8571\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.4838 - accuracy: 0.7407 - val_loss: 0.4148 - val_accuracy: 0.8571\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.3430 - accuracy: 0.8704 - val_loss: 0.4082 - val_accuracy: 0.8571\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3540 - accuracy: 0.8889 - val_loss: 0.4013 - val_accuracy: 0.8571\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.3828 - accuracy: 0.8889 - val_loss: 0.3945 - val_accuracy: 0.8571\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.3848 - accuracy: 0.9074 - val_loss: 0.3879 - val_accuracy: 0.8571\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.3658 - accuracy: 0.8519 - val_loss: 0.3813 - val_accuracy: 0.8571\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.4929 - accuracy: 0.8148 - val_loss: 0.3752 - val_accuracy: 0.8571\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.3428 - accuracy: 0.8704 - val_loss: 0.3691 - val_accuracy: 0.8571\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.3292 - accuracy: 0.8889 - val_loss: 0.3634 - val_accuracy: 0.8571\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3428 - accuracy: 0.8519 - val_loss: 0.3582 - val_accuracy: 0.8571\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3509 - accuracy: 0.8519 - val_loss: 0.3528 - val_accuracy: 0.8571\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.3060 - accuracy: 0.8148 - val_loss: 0.3477 - val_accuracy: 0.8571\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3843 - accuracy: 0.8889 - val_loss: 0.3432 - val_accuracy: 0.8571\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.3175 - accuracy: 0.9074 - val_loss: 0.3387 - val_accuracy: 0.8571\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.3934 - accuracy: 0.8519 - val_loss: 0.3347 - val_accuracy: 0.8571\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.3724 - accuracy: 0.8889 - val_loss: 0.3308 - val_accuracy: 0.8571\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2989 - accuracy: 0.9630 - val_loss: 0.3273 - val_accuracy: 0.8571\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.3324 - accuracy: 0.9444 - val_loss: 0.3239 - val_accuracy: 0.8571\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.2953 - accuracy: 0.9630 - val_loss: 0.3205 - val_accuracy: 0.8571\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2775 - accuracy: 0.9074 - val_loss: 0.3170 - val_accuracy: 0.8571\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.2803 - accuracy: 0.9444 - val_loss: 0.3138 - val_accuracy: 0.8571\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2367 - accuracy: 0.9259 - val_loss: 0.3111 - val_accuracy: 0.8571\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.2718 - accuracy: 0.9630 - val_loss: 0.3086 - val_accuracy: 0.8571\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.2571 - accuracy: 0.8889 - val_loss: 0.3069 - val_accuracy: 0.8571\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2352 - accuracy: 0.9444 - val_loss: 0.3053 - val_accuracy: 0.8571\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2053 - accuracy: 0.9630 - val_loss: 0.3035 - val_accuracy: 0.8571\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.2746 - accuracy: 0.9630 - val_loss: 0.3026 - val_accuracy: 0.8571\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2317 - accuracy: 0.9259 - val_loss: 0.3019 - val_accuracy: 0.8571\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.2458 - accuracy: 0.9259 - val_loss: 0.3016 - val_accuracy: 0.8571\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.2181 - accuracy: 0.9259 - val_loss: 0.3016 - val_accuracy: 0.8571\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.3163 - accuracy: 0.8704 - val_loss: 0.3012 - val_accuracy: 0.8571\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.2355 - accuracy: 0.9074 - val_loss: 0.3009 - val_accuracy: 0.8571\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.2087 - accuracy: 0.9259 - val_loss: 0.3004 - val_accuracy: 0.8571\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.2348 - accuracy: 0.9444 - val_loss: 0.3003 - val_accuracy: 0.8571\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.2058 - accuracy: 0.9444 - val_loss: 0.3000 - val_accuracy: 0.8571\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.2303 - accuracy: 0.9074 - val_loss: 0.3001 - val_accuracy: 0.8571\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.2278 - accuracy: 0.8889 - val_loss: 0.3003 - val_accuracy: 0.7857\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.2889 - accuracy: 0.9259 - val_loss: 0.3009 - val_accuracy: 0.7857\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.2022 - accuracy: 0.9444 - val_loss: 0.3020 - val_accuracy: 0.7857\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.3138 - accuracy: 0.9259 - val_loss: 0.3029 - val_accuracy: 0.7857\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.2076 - accuracy: 0.9630 - val_loss: 0.3040 - val_accuracy: 0.7857\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1898 - accuracy: 0.9444 - val_loss: 0.3051 - val_accuracy: 0.8571\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1438 - accuracy: 0.9444 - val_loss: 0.3060 - val_accuracy: 0.8571\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.1353 - accuracy: 0.9630 - val_loss: 0.3073 - val_accuracy: 0.8571\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.2139 - accuracy: 0.9630 - val_loss: 0.3087 - val_accuracy: 0.8571\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.1849 - accuracy: 0.9630 - val_loss: 0.3103 - val_accuracy: 0.8571\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1968 - accuracy: 0.9630 - val_loss: 0.3119 - val_accuracy: 0.8571\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.2167 - accuracy: 0.9074 - val_loss: 0.3141 - val_accuracy: 0.8571\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.2723 - accuracy: 0.9259 - val_loss: 0.3164 - val_accuracy: 0.8571\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.1737 - accuracy: 0.9630 - val_loss: 0.3189 - val_accuracy: 0.8571\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.1578 - accuracy: 0.9630 - val_loss: 0.3210 - val_accuracy: 0.8571\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1905 - accuracy: 0.9259 - val_loss: 0.3228 - val_accuracy: 0.8571\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.2087 - accuracy: 0.9074 - val_loss: 0.3245 - val_accuracy: 0.8571\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2007 - accuracy: 0.9259 - val_loss: 0.3273 - val_accuracy: 0.8571\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1674 - accuracy: 0.9074 - val_loss: 0.3299 - val_accuracy: 0.8571\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2626 - accuracy: 0.9444 - val_loss: 0.3334 - val_accuracy: 0.8571\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1398 - accuracy: 0.9444 - val_loss: 0.3372 - val_accuracy: 0.8571\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1623 - accuracy: 0.9630 - val_loss: 0.3411 - val_accuracy: 0.8571\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1865 - accuracy: 0.9259 - val_loss: 0.3445 - val_accuracy: 0.8571\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.2019 - accuracy: 0.9259 - val_loss: 0.3470 - val_accuracy: 0.8571\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2133 - accuracy: 0.9444 - val_loss: 0.3490 - val_accuracy: 0.8571\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.2094 - accuracy: 0.9630 - val_loss: 0.3519 - val_accuracy: 0.8571\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1756 - accuracy: 0.9074 - val_loss: 0.3546 - val_accuracy: 0.8571\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1557 - accuracy: 0.9630 - val_loss: 0.3575 - val_accuracy: 0.8571\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.1247 - accuracy: 0.9444 - val_loss: 0.3606 - val_accuracy: 0.8571\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1981 - accuracy: 0.9259 - val_loss: 0.3637 - val_accuracy: 0.8571\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.1681 - accuracy: 0.9444 - val_loss: 0.3667 - val_accuracy: 0.8571\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1287 - accuracy: 0.9630 - val_loss: 0.3694 - val_accuracy: 0.8571\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1350 - accuracy: 0.9630 - val_loss: 0.3721 - val_accuracy: 0.8571\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1610 - accuracy: 0.9444 - val_loss: 0.3741 - val_accuracy: 0.8571\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1293 - accuracy: 0.9444 - val_loss: 0.3762 - val_accuracy: 0.8571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo-sTJ6MzaHM",
        "outputId": "d84c8794-e688-4fc4-a61a-c10c4933b2bc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0297 - accuracy: 1.0000\n",
            "Test Loss: 0.029707245528697968\n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цей код створює простий CNN для класифікації рукописних цифр. Спочатку він завантажує і нормалізує набір даних MNIST, потім створює сверточну нейронну сеть, навчає її на дані і оцінює на тестовому наборі даних."
      ],
      "metadata": {
        "id": "2YsFk9h-DSqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Шаг 1: Загрузка данных MNIST\n",
        "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Нормализация данных: Преобразуем значения пикселей из диапазона [0, 255] в [0, 1]\n",
        "mnist_train_images = mnist_train_images / 255.0\n",
        "mnist_test_images = mnist_test_images / 255.0\n",
        "\n",
        "# Решейпинг данных для CNN\n",
        "mnist_train_images = mnist_train_images.reshape((-1, 28, 28, 1))\n",
        "mnist_test_images = mnist_test_images.reshape((-1, 28, 28, 1))\n",
        "\n",
        "# Шаг 2: Создание модели CNN\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Шаг 3: Компиляция модели\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Шаг 4: Обучение модели\n",
        "model.fit(mnist_train_images, mnist_train_labels, epochs=5, batch_size=64)\n",
        "\n",
        "# Шаг 5: Оценка модели\n",
        "test_loss, test_acc = model.evaluate(mnist_test_images, mnist_test_labels)\n",
        "print(f\"Точность на тестовых данных: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVu_kW4JBZFf",
        "outputId": "023145aa-1095-4233-8f86-9ed98b6a3074"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 72s 74ms/step - loss: 0.1912 - accuracy: 0.9417\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 53s 56ms/step - loss: 0.0514 - accuracy: 0.9838\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 52s 55ms/step - loss: 0.0354 - accuracy: 0.9890\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 53s 57ms/step - loss: 0.0287 - accuracy: 0.9909\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 51s 54ms/step - loss: 0.0239 - accuracy: 0.9924\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0259 - accuracy: 0.9923\n",
            "Точность на тестовых данных: 0.9923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "\n",
        "data = pd.read_csv('googleplaystore_user_reviews.csv')\n",
        "# Data Preprocessing\n",
        "# Remove NaN values\n",
        "data.dropna(subset=['Translated_Review', 'Sentiment'], inplace=True)\n",
        "\n",
        "# Text Cleaning function\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning\n",
        "data['Translated_Review'] = data['Translated_Review'].apply(clean_text)\n",
        "\n",
        "# Splitting the dataset into features and target\n",
        "X = data['Translated_Review']\n",
        "y = data['Sentiment']\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Tokenization and Padding\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_seq = tokenizer.texts_to_sequences(X)\n",
        "X_pad = pad_sequences(X_seq, maxlen=100)\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pad, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Building the Bidirectional LSTM model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 128, input_length=100))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax')) # 3 for three sentiment categories\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJutJPpESrk6",
        "outputId": "f6a3021b-e307-47e3-f2c3-4e38e31e5b1c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 100, 128)          3157376   \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 128)               98816     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3264643 (12.45 MB)\n",
            "Trainable params: 3264643 (12.45 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ]
}